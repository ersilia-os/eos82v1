Identifier: eos82v1
Slug: smi-ted
Status: Ready
Title: SMILES-based Transformer Encoder-Decoder
Description: SMILES-based Transformer Encoder-Decoder (SMILES-TED) is an 
  encoder-decoder model pre-trained on a curated dataset of 91 million SMILES 
  samples sourced from PubChem, equivalent to 4 billion molecular tokens. 
  SMI-TED supports various complex tasks, including quantum property prediction,
  with two main variants (289 M and  8x289 M). SMI Ted has been developed by the
  IBM.
Deployment:
  - Local
Source: Local
Source Type: External
Task: Representation
Subtask: Featurization
Input:
  - Compound
Input Dimension: 1
Output:
  - Value
Output Dimension: 768
Output Consistency: Fixed
Interpretation: Embedding of the molecule
Tag:
  - Embedding
  - Descriptor
  - Chemical language model
Biomedical Area:
  - Any
Target Organism:
  - Any
Publication Type: Peer reviewed
Publication Year: 2025
Publication: https://www.nature.com/articles/s42004-025-01585-0
Source Code: https://github.com/IBM/materials
License: Apache-2.0
Incorporation Date: '2025-11-29'
Last Packaging Date: '2025-12-03'
Release: v1.0.0
S3: https://ersilia-models-zipped.s3.eu-central-1.amazonaws.com/eos82v1.zip
DockerHub: https://hub.docker.com/r/ersiliaos/eos82v1
Docker Architecture:
  - AMD64
  - ARM64
Model Size: 1103.0
Environment Size: 7881.0
Image Size: 11113.45
Computational Performance 1: 32.74
Computational Performance 2: 22.96
Computational Performance 3: 33.52
Computational Performance 4: 157.31
Computational Performance 5: 707.81
